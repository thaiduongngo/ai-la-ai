{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60497f0a-2410-41a0-a434-13990f222673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import ollama\n",
    "import requests\n",
    "from IPython import display\n",
    "from langchain_core.prompts  import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc63d96-f4d9-42db-b0d1-b608c7e7cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM options\n",
    "llm_options = {\n",
    "  \"temperature\": 0,\n",
    "  \"num_ctx\": 2048,\n",
    "  \"num_predict\": 4096,\n",
    "  \"top_k\": 20,\n",
    "  \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "# Do \"ollama pull' to fetch a model to local. E.g: ollama pull gemma3:4b\n",
    "gemma3_12b = \"gemma3:12b\"\n",
    "gemma3_4b = \"gemma3:4b\"\n",
    "gemma3_1b = \"gemma3:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82db7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call via REST API\n",
    "def gen_content(\n",
    "    prompts : List[str],\n",
    "    system_prompt : str=None,\n",
    "    model : str=\"llama3.2\",\n",
    "    options : Dict=None) -> str:\n",
    "\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    messages = []\n",
    "    if system_prompt is not None:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for prompt in prompts:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False,\n",
    "        \"options\": options\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    res = requests.post(\n",
    "        url=url,\n",
    "        headers=headers,\n",
    "        json=data\n",
    "    )\n",
    "    \n",
    "    return res.json()[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def gen_content_direct_api(\n",
    "    prompts : List[str],\n",
    "    system_prompt : str=None,\n",
    "    model : str=\"llama3.2\",\n",
    "    options : Dict=None) -> str:\n",
    "    \n",
    "    messages = []\n",
    "\n",
    "    if system_prompt is not None:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for prompt in prompts:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        options=options,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return res['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38601373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Để giải phương trình bậc hai $x^2 + 7x - 3 = 0$, ta có thể sử dụng công thức nghiệm của phương trình bậc hai:\n",
       "\n",
       "$x = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$\n",
       "\n",
       "Trong đó, $a = 1$, $b = 7$, và $c = -3$.\n",
       "\n",
       "Thay các giá trị này vào công thức, ta được:\n",
       "\n",
       "$x = \\dfrac{-7 \\pm \\sqrt{7^2 - 4(1)(-3)}}{2(1)}$\n",
       "$x = \\dfrac{-7 \\pm \\sqrt{49 + 12}}{2}$\n",
       "$x = \\dfrac{-7 \\pm \\sqrt{61}}{2}$\n",
       "\n",
       "Vậy, phương trình có hai nghiệm:\n",
       "\n",
       "$x_1 = \\dfrac{-7 + \\sqrt{61}}{2}$\n",
       "$x_2 = \\dfrac{-7 - \\sqrt{61}}{2}$\n",
       "\n",
       "Vậy nghiệm của phương trình là $x_1 = \\dfrac{-7 + \\sqrt{61}}{2}$ và $x_2 = \\dfrac{-7 - \\sqrt{61}}{2}$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gen_content_direct_api(\n",
    "    prompts=[\"Giải phương trình: x^2 + 7x - 3 = 0\"],\n",
    "    model=gemma3_12b,\n",
    ")\n",
    "\n",
    "display.Markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71100891",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Câu hỏi: {question}\n",
    "\n",
    "Trả lời: suy nghĩ từng bước và trả lời câu hỏi trên\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOllama(model=gemma3_12b, temperature=0)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2746622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Được rồi, hãy cùng nhau giải thích self-attention trong Transformer một cách chi tiết, từng bước một. Tôi sẽ cố gắng làm cho nó dễ hiểu nhất có thể, chia nhỏ các khái niệm và sử dụng ví dụ minh họa.\n",
      "\n",
      "**1. Bối cảnh: Tại sao cần Attention?**\n",
      "\n",
      "* **RNNs và vấn đề về chuỗi dài:** Trước Transformer, các mô hình recurrent neural networks (RNNs) như LSTM và GRU thường được sử dụng để xử lý dữ liệu chuỗi (ví dụ: văn bản). Tuy nhiên, RNNs gặp khó khăn khi xử lý các chuỗi rất dài. Thông tin từ các phần đầu của chuỗi có thể bị \"mất\" khi truyền qua nhiều bước thời gian.\n",
      "* **Attention là gì?**  Attention là một cơ chế cho phép mô hình tập trung vào các phần quan trọng nhất của chuỗi đầu vào khi tạo ra đầu ra. Nó giúp mô hình \"nhớ\" thông tin quan trọng hơn và giảm thiểu vấn đề \"mất thông tin\" trong các chuỗi dài.\n",
      "* **Attention trong Transformer:** Transformer sử dụng một dạng đặc biệt của attention gọi là \"self-attention\".  Điểm khác biệt là self-attention cho phép mỗi từ trong chuỗi đầu vào \"tự\" chú ý đến các từ khác trong cùng chuỗi đó.\n",
      "\n",
      "**2. Self-Attention hoạt động như thế nào?**\n",
      "\n",
      "Hãy tưởng tượng bạn đang đọc câu: \"The cat sat on the mat.\"  Để hiểu câu này, bạn cần liên hệ giữa các từ. Ví dụ, \"cat\" là chủ ngữ của động từ \"sat\". Self-attention giúp mô hình làm điều này.\n",
      "\n",
      "Dưới đây là các bước chính:\n",
      "\n",
      "* **Bước 1: Tạo Queries, Keys và Values:**\n",
      "    * Mỗi từ trong chuỗi đầu vào được biểu diễn bằng một vector (embedding).\n",
      "    * Từ mỗi vector này, chúng ta tạo ra ba vector khác: **Query (Q), Key (K), và Value (V)**.  Điều này được thực hiện bằng cách nhân vector embedding của từ với ba ma trận trọng số khác nhau (WQ, WK, WV).  Các ma trận này là các tham số học được trong quá trình huấn luyện.\n",
      "    * Ví dụ:\n",
      "        * `query = embedding * WQ`\n",
      "        * `key = embedding * WK`\n",
      "        * `value = embedding * WV`\n",
      "    * **Ý nghĩa:**\n",
      "        * **Query (Q):** Đại diện cho \"câu hỏi\" mà từ đang đặt ra cho các từ khác.\n",
      "        * **Key (K):** Đại diện cho \"thông tin\" mà từ cung cấp để trả lời các câu hỏi.\n",
      "        * **Value (V):** Đại diện cho \"nội dung\" mà từ sẽ đóng góp vào đầu ra nếu nó được coi là quan trọng.\n",
      "\n",
      "* **Bước 2: Tính toán Attention Scores:**\n",
      "    * Đối với mỗi từ, chúng ta tính toán một \"attention score\" giữa Query của nó và Key của *tất cả* các từ khác trong chuỗi.  Điều này thường được thực hiện bằng cách tính tích vô hướng (dot product) giữa Query và Key.\n",
      "    * `attention_score = Query * Key` (tích vô hướng)\n",
      "    * **Ý nghĩa:**  Attention score cao cho biết từ đó có liên quan đến từ đang xét.\n",
      "\n",
      "* **Bước 3: Chuẩn hóa Attention Scores:**\n",
      "    * Các attention scores được chia cho căn bậc hai của chiều của vector Key (√(dk)).  Điều này giúp ổn định quá trình huấn luyện, đặc biệt khi chiều của vector Key lớn.\n",
      "    * `scaled_attention_score = attention_score / √(dk)`\n",
      "    * **Lý do:**  Khi chiều của vector Key lớn, tích vô hướng có thể trở nên rất lớn, dẫn đến gradient instability trong quá trình huấn luyện. Chia cho √(dk) giúp giảm thiểu vấn đề này.\n",
      "\n",
      "* **Bước 4: Áp dụng Softmax:**\n",
      "    * Các attention scores đã được chuẩn hóa được đưa qua hàm softmax.  Điều này biến chúng thành một phân phối xác suất, tổng bằng 1.\n",
      "    * `attention_weights = softmax(scaled_attention_score)`\n",
      "    * **Ý nghĩa:**  Attention weights cho biết mức độ quan trọng của mỗi từ khác đối với từ đang xét.\n",
      "\n",
      "* **Bước 5: Tính toán Weighted Values:**\n",
      "    * Các attention weights được sử dụng để tính toán một tổng có trọng số của các Value vectors.\n",
      "    * `weighted_value = attention_weights * Value`\n",
      "    * **Ý nghĩa:**  Các Value vectors của các từ có attention weights cao sẽ đóng góp nhiều hơn vào đầu ra.\n",
      "\n",
      "* **Bước 6: Kết hợp các Weighted Values:**\n",
      "    * Các weighted values của tất cả các từ được cộng lại để tạo ra một vector đầu ra duy nhất cho từ đang xét.\n",
      "    * `output = sum(weighted_value)`\n",
      "\n",
      "**3. Multi-Head Attention**\n",
      "\n",
      "* **Ý tưởng:** Thay vì chỉ sử dụng một bộ ma trận trọng số (WQ, WK, WV), Multi-Head Attention sử dụng nhiều bộ (ví dụ: 8 bộ).  Mỗi bộ tạo ra một \"head\" (đầu) attention.\n",
      "* **Lợi ích:**  Mỗi head có thể học được các mối quan hệ khác nhau giữa các từ.  Ví dụ, một head có thể tập trung vào mối quan hệ cú pháp, trong khi một head khác có thể tập trung vào mối quan hệ ngữ nghĩa.\n",
      "* **Kết hợp:**  Đầu ra của tất cả các heads được nối lại và sau đó được đưa qua một lớp tuyến tính để tạo ra đầu ra cuối cùng.\n",
      "\n",
      "**4. Tóm tắt và Ví dụ**\n",
      "\n",
      "Hãy quay lại câu \"The cat sat on the mat.\"\n",
      "\n",
      "* **Từ \"cat\":** Query của \"cat\" sẽ được so sánh với Key của tất cả các từ khác.  Có thể \"cat\" có attention score cao với \"sat\" (vì \"cat\" là chủ ngữ của \"sat\").\n",
      "* **Từ \"sat\":** Query của \"sat\" có thể có attention score cao với \"cat\" và \"mat\" (vì \"sat\" liên quan đến cả chủ ngữ và trạng ngữ).\n",
      "* **Từ \"mat\":** Query của \"mat\" có thể có attention score cao với \"sat\" (vì \"mat\" là nơi mà \"cat\" ngồi).\n",
      "\n",
      "**5. Tại sao Self-Attention lại quan trọng trong Transformer?**\n",
      "\n",
      "* **Xử lý song song:**  Self-attention có thể được tính toán song song cho tất cả các từ trong chuỗi, điều này nhanh hơn nhiều so với các mô hình recurrent.\n",
      "* **Mô hình hóa các phụ thuộc xa:**  Self-attention có thể mô hình hóa các phụ thuộc giữa các từ ở xa trong chuỗi một cách hiệu quả.\n",
      "* **Giải thích:**  Attention weights có thể được sử dụng để giải thích cách mô hình đưa ra quyết định.\n",
      "\n",
      "**Để hiểu sâu hơn:**\n",
      "\n",
      "* **Hình ảnh minh họa:** Tìm kiếm trên Google hình ảnh \"self-attention visualization\" để thấy trực quan cách attention weights thay đổi.\n",
      "* **Code:**  Tìm kiếm các ví dụ code về self-attention trong PyTorch hoặc TensorFlow.\n",
      "* **Bài báo gốc:** Đọc bài báo \"Attention is All You Need\" (Vaswani et al., 2017).\n",
      "\n",
      "Hy vọng giải thích này giúp bạn hiểu rõ hơn về self-attention trong Transformer!  Nếu bạn có bất kỳ câu hỏi nào khác, đừng ngần ngại hỏi.\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream({\n",
    "    \"question\": \"Giải thích self-attention trong Transformer?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fccff0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Được thôi, chúng ta hãy cùng suy nghĩ từng bước để trả lời câu hỏi \"Vận tốc ánh sáng có phải là tuyệt đối?\".\n",
      "\n",
      "**1. Định nghĩa \"Tuyệt đối\"**\n",
      "\n",
      "Trước hết, chúng ta cần hiểu \"tuyệt đối\" nghĩa là gì. Một đại lượng tuyệt đối là một đại lượng không thay đổi, không phụ thuộc vào bất kỳ yếu tố nào khác. Nó là một hằng số thực sự.\n",
      "\n",
      "**2. Vận tốc ánh sáng là gì?**\n",
      "\n",
      "Vận tốc ánh sáng (ký hiệu là *c*) là tốc độ mà ánh sáng truyền đi trong chân không. Nó có giá trị xấp xỉ 299.792.458 mét trên giây.\n",
      "\n",
      "**3. Các quan điểm lịch sử và thí nghiệm:**\n",
      "\n",
      "*   **Trước Einstein:** Người ta từng nghĩ rằng vận tốc ánh sáng là tương đối, nghĩa là nó có thể thay đổi tùy thuộc vào chuyển động của người quan sát.\n",
      "*   **Thí nghiệm Michelson-Morley (1887):** Thí nghiệm này được thiết kế để phát hiện sự thay đổi của vận tốc ánh sáng do Trái Đất chuyển động trong \"ether\" (một môi trường giả định mà ánh sáng được cho là truyền qua). Kết quả thí nghiệm lại cho thấy không có sự thay đổi nào cả. Điều này gây ra một cuộc cách mạng trong vật lý.\n",
      "*   **Thuyết tương đối đặc biệt của Einstein (1905):** Einstein đã đưa ra thuyết tương đối đặc biệt, trong đó một trong những tiên đề chính là vận tốc ánh sáng trong chân không là một hằng số, không phụ thuộc vào chuyển động của nguồn sáng hoặc người quan sát.\n",
      "\n",
      "**4. Kết luận:**\n",
      "\n",
      "Dựa trên thuyết tương đối đặc biệt của Einstein và vô số bằng chứng thực nghiệm, chúng ta có thể kết luận rằng **vận tốc ánh sáng trong chân không là tuyệt đối**. Nó là một hằng số vũ trụ, không thay đổi.\n",
      "\n",
      "**Tuy nhiên, cần lưu ý một vài điểm:**\n",
      "\n",
      "*   **Trong môi trường khác chân không:** Vận tốc ánh sáng có thể chậm lại khi nó truyền qua các môi trường như nước, thủy tinh, hoặc không khí. Tuy nhiên, điều này không làm thay đổi sự thật rằng nó là tuyệt đối trong chân không.\n",
      "*   **Các lý thuyết khác:** Một số lý thuyết vật lý hiện đại (như lý thuyết dây) dự đoán rằng vận tốc ánh sáng có thể không hoàn toàn tuyệt đối ở những điều kiện cực đoan, nhưng những dự đoán này vẫn chưa được kiểm chứng.\n",
      "\n",
      "**Tóm lại:** Trong hầu hết các trường hợp và theo hiểu biết hiện tại của chúng ta, vận tốc ánh sáng là tuyệt đối."
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream({\n",
    "    \"question\": \"Vận tốc ánh sáng có phải là tuyệt đối?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12813e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./data.txt\")\n",
    "text = loader.load()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a949109",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = (\n",
    "    \"system\",\n",
    "    \"Bạn là tư vấn viên về tài chính và bảo hiểm. Hãy giải đáp các thắc mắc của khách hàng về các loại sản phẩm bảo hiểm. Nếu cần hãy giải thích chi tiết và dễ hiểu nhất có thể\",\n",
    ")\n",
    "\n",
    "user_template = (\"user\",\n",
    "\"\"\"\n",
    "Thông tin: {text}\n",
    "\n",
    "\n",
    "Câu hỏi: {question}\n",
    "\n",
    "\n",
    "Trả lời câu hỏi dựa trên thông tin được cung cấp. Nếu không tìm thấy thông tin, hãy trả lời \\\"Tôi chưa được cập nhật thông tin này\\\"\n",
    "\"\"\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([system_prompt_template, user_template])\n",
    "\n",
    "chain1 = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44692f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chào bạn,\n",
      "\n",
      "Dựa trên thông tin được cung cấp, các quyền lợi nổi bật của sản phẩm bảo hiểm liên kết đơn vị PRU-ĐẦU TƯ LINH HOẠT bao gồm:\n",
      "\n",
      "*   **Cơ hội đầu tư và gia tăng tài sản:** Thông qua 07 quỹ PRUlink được quản lý bởi đội ngũ chuyên gia giàu kinh nghiệm.\n",
      "*   **Bảo vệ tài chính gia đình:** 100% Số tiền bảo hiểm và toàn bộ kết quả đầu tư sẽ được chi trả.\n",
      "*   **Linh hoạt:** Bạn có thể chủ động quyết định kế hoạch bảo vệ tài chính và đầu tư, bao gồm lựa chọn/thay đổi tỷ lệ đầu tư, hoán đổi quỹ, đầu tư thêm, miễn phí rút tiền và điều chỉnh hạn mức bảo vệ.\n",
      "*   **Quyền lợi khi kết thúc hợp đồng:** 100% Giá trị Quỹ hợp đồng.\n",
      "*   **Quyền lợi tử vong và thương tật toàn bộ vĩnh viễn:** 100% Số tiền bảo hiểm (STBH) + Giá trị quỹ hợp đồng.\n",
      "*   **Thay đổi quyền lợi bảo hiểm sau tuổi 70:** Bạn có quyền thay đổi một lần về lựa chọn quyền lợi bảo hiểm.\n",
      "*   **Quà tặng:** Có quà tặng tham gia hợp đồng giá trị lớn và khoản thưởng duy trì hợp đồng cho những khách hàng đáp ứng điều kiện.\n",
      "\n",
      "Hy vọng thông tin này hữu ích cho bạn!"
     ]
    }
   ],
   "source": [
    "async for chunk in chain1.astream({\n",
    "    \"text\": text,\n",
    "    \"question\": \"Các quyền lợi nổi bật của Pru đầu tư linh hoạt?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01f3fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi chưa được cập nhật thông tin này. Thông tin được cung cấp không đề cập đến các điều khoản loại trừ của sản phẩm PRU-ĐẦU TƯ LINH HOẠT."
     ]
    }
   ],
   "source": [
    "async for chunk in chain1.astream({\n",
    "    \"text\": text,\n",
    "    \"question\": \"Thông tin về điều khoản loại trừ của Pru đầu tư linh hoạt?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbff93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRU-ĐẦU TƯ LINH HOẠT là một giải pháp kết hợp giữa bảo hiểm và đầu tư, giúp bạn vừa được bảo vệ tài chính trước rủi ro, vừa có cơ hội gia tăng tài sản. Sản phẩm này cho phép bạn chủ động quyết định kế hoạch bảo vệ tài chính và đầu tư của mình, với nhiều quyền lợi ưu việt như:\n",
      "\n",
      "*   **Cơ hội đầu tư:** Thông qua các quỹ PRUlink với nhiều mức độ chấp nhận rủi ro khác nhau.\n",
      "*   **Bảo vệ tài chính:** 100% Số tiền bảo hiểm và toàn bộ kết quả đầu tư.\n",
      "*   **Linh hoạt:** Hoán đổi quỹ, đầu tư thêm hay rút tiền mà không mất chi phí.\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chain1.astream({\n",
    "    \"text\": text,\n",
    "    \"question\": \"Pru đầu tư linh hoạt là gì?\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-la-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
